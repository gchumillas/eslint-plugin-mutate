name: Performance Benchmarks

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      benchmark_type:
        description: 'Type of benchmark to run'
        required: false
        default: 'full'
        type: choice
        options:
        - full
        - regression-only
        - rules-only

jobs:
  performance:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    strategy:
      matrix:
        node-version: [16, 18, 20]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 3  # Need history for comparison

    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run tests first
      run: npm test

    - name: Create results directory
      run: mkdir -p benchmarks/results

    - name: Run full benchmarks
      if: github.event.inputs.benchmark_type == 'full' || github.event.inputs.benchmark_type == ''
      run: |
        echo "ðŸš€ Running full benchmark suite..."
        npm run benchmark 2>&1 | tee benchmarks/results/benchmark-node${{ matrix.node-version }}.log

    - name: Run rule-specific benchmarks
      if: github.event.inputs.benchmark_type == 'full' || github.event.inputs.benchmark_type == 'rules-only' || github.event.inputs.benchmark_type == ''
      run: |
        echo "ðŸŽ¯ Running rule-specific benchmarks..."
        npm run benchmark:rules 2>&1 | tee benchmarks/results/rules-node${{ matrix.node-version }}.log

    - name: Run regression check
      if: github.event_name == 'pull_request' || github.event.inputs.benchmark_type == 'regression-only'
      run: |
        echo "ðŸ” Checking for performance regressions..."
        npm run benchmark:regression 2>&1 | tee benchmarks/results/regression-node${{ matrix.node-version }}.log
      continue-on-error: false

    - name: Generate performance report
      run: |
        echo "ðŸ“Š Generating performance report..."
        cat > benchmarks/results/summary-node${{ matrix.node-version }}.json << EOF
        {
          "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
          "node_version": "${{ matrix.node-version }}",
          "commit": "${{ github.sha }}",
          "branch": "${{ github.ref_name }}",
          "event": "${{ github.event_name }}",
          "benchmark_type": "${{ github.event.inputs.benchmark_type || 'full' }}",
          "status": "completed"
        }
        EOF

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-results-node${{ matrix.node-version }}
        path: benchmarks/results/
        retention-days: 30

    - name: Comment PR with results
      if: github.event_name == 'pull_request' && matrix.node-version == '18'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          try {
            // Read benchmark results
            const benchmarkLog = fs.readFileSync('benchmarks/results/benchmark-node18.log', 'utf8');
            const regressionLog = fs.readFileSync('benchmarks/results/regression-node18.log', 'utf8');
            
            // Extract key metrics (simplified)
            const summaryMatch = benchmarkLog.match(/ðŸ“‹ SUMMARY[\s\S]*?(?=\n\n|\n$|$)/);
            const summary = summaryMatch ? summaryMatch[0] : 'Could not extract summary';
            
            const regressionMatch = regressionLog.match(/âœ….*regressions|âŒ.*regression/);
            const regressionStatus = regressionMatch ? regressionMatch[0] : 'Regression check completed';
            
            const comment = `## ðŸš€ Performance Benchmark Results
            
            **Node.js 18 Results:**
            
            ### Regression Check
            ${regressionStatus}
            
            ### Performance Summary
            \`\`\`
            ${summary.slice(0, 1000)}${summary.length > 1000 ? '...' : ''}
            \`\`\`
            
            <details>
            <summary>ðŸ“Š View detailed results</summary>
            
            Full benchmark results are available in the [workflow artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).
            
            </details>
            
            _Performance benchmarks run on Node.js 16, 18, and 20. Results shown are from Node.js 18._`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.log('Could not post comment:', error.message);
          }

  benchmark-comparison:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: performance
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 10

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Download benchmark results
      uses: actions/download-artifact@v4
      with:
        name: performance-results-node18
        path: benchmarks/results/

    - name: Compare with main branch
      run: |
        echo "ðŸ” Comparing performance with main branch..."
        npm run benchmark:compare -- --output benchmarks/results/comparison.json 2>&1 | tee benchmarks/results/comparison.log || true

    - name: Upload comparison results
      uses: actions/upload-artifact@v4
      with:
        name: performance-comparison
        path: benchmarks/results/comparison*
        retention-days: 30
